{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descompactando as pastas   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def descompactar_arquivo(arquivo_zip, pasta_destino):\n",
    "    with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)\n",
    "        print(f'Arquivo {arquivo_zip} descompactado para {pasta_destino}')\n",
    "\n",
    "def descompactar_varias_pastas(pasta_origem, pasta_destino):\n",
    "    if not os.path.exists(pasta_destino):\n",
    "        os.makedirs(pasta_destino)\n",
    "\n",
    "    for arquivo_zip in os.listdir(pasta_origem):\n",
    "        if arquivo_zip.endswith('.zip'):\n",
    "            caminho_arquivo_zip = os.path.join(pasta_origem, arquivo_zip)\n",
    "            nome_pasta = os.path.splitext(arquivo_zip)[0]\n",
    "            pasta_destino_completa = os.path.join(pasta_destino, nome_pasta)\n",
    "\n",
    "            if not os.path.exists(pasta_destino_completa):\n",
    "                os.makedirs(pasta_destino_completa)\n",
    "\n",
    "            descompactar_arquivo(caminho_arquivo_zip, pasta_destino_completa)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Pasta contendo os arquivos ZIP\n",
    "    pasta_origem = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5\"\n",
    "\n",
    "    # Pasta de destino para os arquivos descompactados\n",
    "    pasta_destino = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5\"\n",
    "\n",
    "    descompactar_varias_pastas(pasta_origem, pasta_destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funçoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(folder):\n",
    "    import os\n",
    "\n",
    "    # Divida o caminho usando a barra invertida como delimitador\n",
    "    partes_do_caminho = folder.split('\\\\')\n",
    "\n",
    "    # O penúltimo elemento deve ser o ID do paciente\n",
    "    if len(partes_do_caminho) >= 2:\n",
    "        paciente_id = partes_do_caminho[-2]\n",
    "        return paciente_id\n",
    "    else:\n",
    "        return None  # Retorna None se não puder extrair o ID do paciente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(file):\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "\n",
    "    df = pd.read_csv(file, header=None)\n",
    "    timestamp = df.iloc[0, 0]\n",
    "    dt_object = datetime.datetime.fromtimestamp(timestamp)\n",
    "    date_string = dt_object.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    return date_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23/07/2020 16:52:58'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5\\F5_1595533978\\ACC.csv\"\n",
    "s = get_timestamp(file)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_ACC(acc):\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    acc_df= pd.read_csv(acc, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice, coluna in acc_df.iterrows():\n",
    "        user_distancex = coluna.iloc[0]\n",
    "        user_distancey = coluna.iloc[1]\n",
    "        user_distancez = coluna.iloc[2]\n",
    "        vetor.append(math.sqrt(user_distancex**2 + user_distancey**2 + user_distancez**2))\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_EDA(eda):\n",
    "    import pandas as pd\n",
    "    eda_df= pd.read_csv(eda, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in eda_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_HR(hr):\n",
    "    import pandas as pd\n",
    "    hr_df= pd.read_csv(hr, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in hr_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_TEMP(temp):\n",
    "    import pandas as pd\n",
    "    temp_df= pd.read_csv(temp, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in temp_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho de acc:  655446\n",
      "tamanho de eda:  81930\n",
      "tamanho de hr:  20473\n",
      "tamanho de temp:  81928\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D\\6D_1594910470\\ACC.csv\"\n",
    "b = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D\\6D_1594910470\\EDA.csv\"\n",
    "c = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D\\6D_1594910470\\HR.csv\"\n",
    "d = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D\\6D_1594910470\\TEMP.csv\"\n",
    "acc = get_info_ACC(a)\n",
    "eda = get_info_EDA(b)\n",
    "hr = get_info_HR(c)\n",
    "temp = get_info_TEMP(d)\n",
    "print(\"tamanho de acc: \", len(acc))\n",
    "print(\"tamanho de eda: \", len(eda))\n",
    "print(\"tamanho de hr: \", len(hr))\n",
    "print(\"tamanho de temp: \", len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "caminho_raiz = os.path.join(os.getcwd(), 'Stress_dataset', '6D')\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "        data_ACC, data_EDA, data_HR, data_TEMP = None, None, None, None\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "        nova_linha = {'ID': id, 'TIMESTAMP': timestamp, 'ACC': data_ACC, 'EDA': data_EDA, 'HR': data_HR, 'TEMP': data_TEMP, 'STRESS': np.nan}\n",
    "\n",
    "        array = np.array(list(nova_linha.values()), dtype=object)\n",
    "        array_t = np.transpose(array)\n",
    "###### Tenta transformar em um np array, dar o transpose e concatenar como vc fez com o pd.concat\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([array_t])], ignore_index=True)\n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "caminho_raiz = os.path.join(os.getcwd(), 'Stress_dataset', '6D')\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "cont = 0\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        \n",
    "        id, timestamp, data_ACC, data_EDA, data_HR, data_TEMP = None, None, None, None, None, None\n",
    "\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "            if cont==0:\n",
    "                df['ID'] = id\n",
    "                df['TIMESTAMP'] = timestamp\n",
    "                df['ACC'] = data_ACC\n",
    "                df['EDA'] = data_EDA\n",
    "                df['HR'] = data_HR\n",
    "                df['TEMP'] = data_TEMP\n",
    "                df['STRESS'] = np.nan\n",
    "                cont = cont + 1\n",
    "            # else:\n",
    "            #     # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([timestamp])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_ACC])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_EDA])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_HR])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_TEMP])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "\n",
    "                # df.append(pd.DataFrame({'ID': id}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TIMESTAMP': timestamp}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'ACC': data_ACC}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'EDA': data_EDA}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'HR': data_HR}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TEMP': data_TEMP}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'STRESS': np.nan}), ignore_index=True)\n",
    "            \n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data_TEMP \u001b[39m=\u001b[39m get_info_EDA(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(caminho_pasta, arquivo))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Convertendo strings para listas usando ast.literal_eval\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mACC\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39;49mliteral_eval(data[\u001b[39m\"\u001b[39;49m\u001b[39mACC\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mEDA\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mliteral_eval(data[\u001b[39m\"\u001b[39m\u001b[39mEDA\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mHR\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mliteral_eval(data[\u001b[39m\"\u001b[39m\u001b[39mHR\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Constant) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mvalue) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m lno \u001b[39m:=\u001b[39m \u001b[39mgetattr\u001b[39m(node, \u001b[39m'\u001b[39m\u001b[39mlineno\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m on line \u001b[39m\u001b[39m{\u001b[39;00mlno\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: []"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "caminho_raiz = os.path.join(os.getcwd(), 'Stress_dataset', '6D')\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "cont = 0\n",
    "\n",
    "data = {\n",
    "        'ID': [],\n",
    "        'TIMESTAMP': [],\n",
    "        'ACC': [],\n",
    "        'EDA': [],\n",
    "        'HR': [],\n",
    "        'TEMP': [],\n",
    "        'STRESS': []\n",
    "        }\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        \n",
    "        stress = []\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "            # Convertendo strings para listas usando ast.literal_eval\n",
    "            data[\"ACC\"] = ast.literal_eval(data[\"ACC\"])\n",
    "            data[\"EDA\"] = ast.literal_eval(data[\"EDA\"])\n",
    "            data[\"HR\"] = ast.literal_eval(data[\"HR\"])\n",
    "            data[\"TEMP\"] = ast.literal_eval(data[\"TEMP\"])\n",
    "            data[\"STRESS\"] = ast.literal_eval(data[\"STRESS\"])\n",
    "            # Convertendo para DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "            # Criando uma nova linha para cada elemento nas listas\n",
    "            df = df.apply(lambda col: col.apply(pd.Series)).stack().reset_index(level=1, drop=True).to_frame().join(df.drop([\"ACC\", \"EDA\", \"HR\", \"TEMP\", \"STRESS\"], axis=1))\n",
    "            df = df.reset_index().rename(columns={0: \"VALUE\"})\n",
    "\n",
    "\n",
    "            # else:\n",
    "            #     # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([timestamp])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_ACC])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_EDA])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_HR])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_TEMP])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "\n",
    "                # df.append(pd.DataFrame({'ID': id}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TIMESTAMP': timestamp}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'ACC': data_ACC}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'EDA': data_EDA}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'HR': data_HR}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TEMP': data_TEMP}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'STRESS': np.nan}), ignore_index=True)\n",
    "            \n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain6.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               6D\n",
      "Start time                 02:00:00\n",
      "End time                   04:00:00\n",
      "duration                   02:00:00\n",
      "date            2020-06-03 00:00:00\n",
      "Stress level                      1\n",
      "Name: 46, dtype: object\n",
      "ID                               6D\n",
      "Start time                 09:49:00\n",
      "End time                   10:24:00\n",
      "duration                   00:35:00\n",
      "date            2020-07-16 00:00:00\n",
      "Stress level                      2\n",
      "Name: 209, dtype: object\n",
      "ID                               6D\n",
      "Start time                 10:37:00\n",
      "End time                   10:48:00\n",
      "duration                   00:11:00\n",
      "date            2020-07-16 00:00:00\n",
      "Stress level                      2\n",
      "Name: 210, dtype: object\n",
      "ID                               6D\n",
      "Start time                 10:57:00\n",
      "End time                   15:19:00\n",
      "duration                   04:22:00\n",
      "date            2020-07-16 00:00:00\n",
      "Stress level                      0\n",
      "Name: 211, dtype: object\n"
     ]
    }
   ],
   "source": [
    "survey = pd.read_excel(r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\SurveyResults.xlsx\", )\n",
    "survey = survey.iloc[:, :6]\n",
    "\n",
    "for index, row in survey.iterrows():\n",
    "    if row.iloc[0] == \"6D\":\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\preprocessing.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X21sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                 data_TEMP \u001b[39m=\u001b[39m get_info_EDA(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(caminho_pasta, arquivo))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X21sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                 data[\u001b[39m'\u001b[39m\u001b[39mTEMP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m data_TEMP            \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X21sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mfrom_dict(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X21sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m6Dagain7.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:1813\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1807\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1808\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for orient parameter. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1809\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00morient\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1810\u001b[0m     )\n\u001b[0;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1813\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(data, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1815\u001b[0m     realdata \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "caminho_raiz = os.path.join(os.getcwd(), 'Stress_dataset', '6D')\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "cont = 0\n",
    "\n",
    "data = {\n",
    "        'ID': [],\n",
    "        'TIMESTAMP': [],\n",
    "        'ACC': [],\n",
    "        'EDA': [],\n",
    "        'HR': [],\n",
    "        'TEMP': [],\n",
    "        'STRESS': []\n",
    "        }\n",
    "id, timestamp, data_ACC, data_EDA, data_HR, data_TEMP = None, None, None, None, None, None\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "    \n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        id = get_id(caminho_pasta)\n",
    "        \n",
    "        #stress = []\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "                data['ACC'] += data_ACC\n",
    "\n",
    "                timestamp = get_timestamp(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "                #data['TIMESTAMP'].append(int(float(timestamp)))\n",
    "                data['ID'].append(str(id))\n",
    "\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "                data['EDA'] += data_EDA\n",
    "\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "                data['HR'] += data_HR\n",
    "\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "                data['TEMP'] += data_TEMP            \n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"6Dagain7.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "      <th>duration</th>\n",
       "      <th>date</th>\n",
       "      <th>Stress level</th>\n",
       "      <th>COVID related</th>\n",
       "      <th>Treating a covid patient</th>\n",
       "      <th>Patient in Crisis</th>\n",
       "      <th>Patient or patient's family</th>\n",
       "      <th>Doctors or colleagues</th>\n",
       "      <th>Administration, lab, pharmacy, radiology, or other ancilliary services\\n</th>\n",
       "      <th>Increased Workload</th>\n",
       "      <th>Technology related stress</th>\n",
       "      <th>Lack of supplies</th>\n",
       "      <th>Documentation</th>\n",
       "      <th>Competency related stress</th>\n",
       "      <th>Saftey (physical or physiological threats)</th>\n",
       "      <th>Work Environment - Physical or others: work processes or procedures</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5C</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5C</td>\n",
       "      <td>17:31:00</td>\n",
       "      <td>17:58:00</td>\n",
       "      <td>00:27:00</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E4</td>\n",
       "      <td>15:32:00</td>\n",
       "      <td>15:37:00</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spoke with family regarding patient's decline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E4</td>\n",
       "      <td>14:05:00</td>\n",
       "      <td>14:11:00</td>\n",
       "      <td>00:06:00</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Was placing another FaceTime call to a patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7A</td>\n",
       "      <td>13:52:00</td>\n",
       "      <td>14:03:00</td>\n",
       "      <td>00:11:00</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>83</td>\n",
       "      <td>23:05:00</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>00:45:00</td>\n",
       "      <td>2020-12-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>83</td>\n",
       "      <td>00:12:00</td>\n",
       "      <td>02:01:00</td>\n",
       "      <td>01:49:00</td>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>83</td>\n",
       "      <td>20:34:00</td>\n",
       "      <td>20:48:00</td>\n",
       "      <td>00:14:00</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>83</td>\n",
       "      <td>20:54:00</td>\n",
       "      <td>21:13:00</td>\n",
       "      <td>00:19:00</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>BG</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>19:38:00</td>\n",
       "      <td>00:18:00</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Start time  End time  duration       date Stress level COVID related  \\\n",
       "0    5C   08:00:00  09:00:00  01:00:00 2020-04-15            1             0   \n",
       "1    5C   17:31:00  17:58:00  00:27:00 2020-04-14            1             0   \n",
       "2    E4   15:32:00  15:37:00  00:05:00 2020-04-18            2             0   \n",
       "3    E4   14:05:00  14:11:00  00:06:00 2020-04-18            2             0   \n",
       "4    7A   13:52:00  14:03:00  00:11:00 2020-04-18            2             0   \n",
       "..   ..        ...       ...       ...        ...          ...           ...   \n",
       "353  83   23:05:00  23:50:00  00:45:00 2020-12-12            2             0   \n",
       "354  83   00:12:00  02:01:00  01:49:00 2020-12-13            2             0   \n",
       "355  83   20:34:00  20:48:00  00:14:00 2020-12-11            2             0   \n",
       "356  83   20:54:00  21:13:00  00:19:00 2020-12-11            2             0   \n",
       "357  BG   19:20:00  19:38:00  00:18:00 2020-12-11            2             0   \n",
       "\n",
       "    Treating a covid patient Patient in Crisis Patient or patient's family  \\\n",
       "0                          1                 0                           1   \n",
       "1                          1                 0                           1   \n",
       "2                          1                 0                           1   \n",
       "3                          0                 0                           1   \n",
       "4                          1                 0                           0   \n",
       "..                       ...               ...                         ...   \n",
       "353                        0                 0                           0   \n",
       "354                        1                 0                           0   \n",
       "355                        1                 0                           0   \n",
       "356                        1                 0                           0   \n",
       "357                        0                 0                           0   \n",
       "\n",
       "    Doctors or colleagues  \\\n",
       "0                       0   \n",
       "1                       0   \n",
       "2                       0   \n",
       "3                       0   \n",
       "4                       0   \n",
       "..                    ...   \n",
       "353                     0   \n",
       "354                     0   \n",
       "355                     0   \n",
       "356                     0   \n",
       "357                     0   \n",
       "\n",
       "    Administration, lab, pharmacy, radiology, or other ancilliary services\\n  \\\n",
       "0                                                    0                         \n",
       "1                                                    0                         \n",
       "2                                                    0                         \n",
       "3                                                    0                         \n",
       "4                                                    0                         \n",
       "..                                                 ...                         \n",
       "353                                                  0                         \n",
       "354                                                  0                         \n",
       "355                                                  0                         \n",
       "356                                                  0                         \n",
       "357                                                  0                         \n",
       "\n",
       "    Increased Workload Technology related stress Lack of supplies  \\\n",
       "0                    0                         0                0   \n",
       "1                    1                         0                0   \n",
       "2                    0                         0                0   \n",
       "3                    0                         0                0   \n",
       "4                    1                         0                0   \n",
       "..                 ...                       ...              ...   \n",
       "353                  0                         0                0   \n",
       "354                  0                         0                0   \n",
       "355                  0                         0                0   \n",
       "356                  0                         0                0   \n",
       "357                  0                         0                0   \n",
       "\n",
       "    Documentation Competency related stress  \\\n",
       "0               0                         0   \n",
       "1               0                         0   \n",
       "2               0                         0   \n",
       "3               0                         0   \n",
       "4               0                         0   \n",
       "..            ...                       ...   \n",
       "353             0                         0   \n",
       "354             0                         0   \n",
       "355             0                         0   \n",
       "356             0                         0   \n",
       "357             0                         0   \n",
       "\n",
       "    Saftey (physical or physiological threats)  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "..                                         ...   \n",
       "353                                          0   \n",
       "354                                          0   \n",
       "355                                          0   \n",
       "356                                          0   \n",
       "357                                          0   \n",
       "\n",
       "    Work Environment - Physical or others: work processes or procedures  \\\n",
       "0                                                    0                    \n",
       "1                                                    0                    \n",
       "2                                                    0                    \n",
       "3                                                    0                    \n",
       "4                                                    1                    \n",
       "..                                                 ...                    \n",
       "353                                                  0                    \n",
       "354                                                  0                    \n",
       "355                                                  0                    \n",
       "356                                                  0                    \n",
       "357                                                  0                    \n",
       "\n",
       "                                           Description  \n",
       "0                                                   na  \n",
       "1                                                   na  \n",
       "2    Spoke with family regarding patient's decline ...  \n",
       "3    Was placing another FaceTime call to a patient...  \n",
       "4                                                   na  \n",
       "..                                                 ...  \n",
       "353                                                 na  \n",
       "354                                                 na  \n",
       "355                                                 na  \n",
       "356                                                 na  \n",
       "357                                                 na  \n",
       "\n",
       "[358 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "file = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\SurveyResults.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
