{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descompactando as pastas   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def descompactar_arquivo(arquivo_zip, pasta_destino):\n",
    "    with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)\n",
    "        print(f'Arquivo {arquivo_zip} descompactado para {pasta_destino}')\n",
    "\n",
    "def descompactar_varias_pastas(pasta_origem, pasta_destino):\n",
    "    if not os.path.exists(pasta_destino):\n",
    "        os.makedirs(pasta_destino)\n",
    "\n",
    "    for arquivo_zip in os.listdir(pasta_origem):\n",
    "        if arquivo_zip.endswith('.zip'):\n",
    "            caminho_arquivo_zip = os.path.join(pasta_origem, arquivo_zip)\n",
    "            nome_pasta = os.path.splitext(arquivo_zip)[0]\n",
    "            pasta_destino_completa = os.path.join(pasta_destino, nome_pasta)\n",
    "\n",
    "            if not os.path.exists(pasta_destino_completa):\n",
    "                os.makedirs(pasta_destino_completa)\n",
    "\n",
    "            descompactar_arquivo(caminho_arquivo_zip, pasta_destino_completa)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Pasta contendo os arquivos ZIP\n",
    "    pasta_origem = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5\"\n",
    "\n",
    "    # Pasta de destino para os arquivos descompactados\n",
    "    pasta_destino = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5\"\n",
    "\n",
    "    descompactar_varias_pastas(pasta_origem, pasta_destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funçoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirar timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(root_folder):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    #root_folder = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\5C\"\n",
    "    numeros = []\n",
    "    ids = []\n",
    "\n",
    "    for pasta in os.listdir(root_folder):\n",
    "        # Extrai a parte do nome da pasta após o underscore\n",
    "        partes_do_nome = pasta.split('_')\n",
    "\n",
    "        if len(partes_do_nome) == 2:\n",
    "            id = partes_do_nome[0]\n",
    "            ids.append(id)\n",
    "            #print(f'Nome da pasta: {pasta}, Número extraído: {numero}')\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(root_folder):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    #root_folder = r\"C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\5C\"\n",
    "    numeros = []\n",
    "    ids = []\n",
    "\n",
    "    for pasta in os.listdir(root_folder):\n",
    "        # Extrai a parte do nome da pasta após o underscore\n",
    "        partes_do_nome = pasta.split('_')\n",
    "\n",
    "        if len(partes_do_nome) == 2:\n",
    "            numero = partes_do_nome[1]\n",
    "            numeros.append(numero)\n",
    "            #print(f'Nome da pasta: {pasta}, Número extraído: {numero}')\n",
    "    return numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def get_info_ACC(acc):\n",
    "    acc_df= pd.read_csv(acc, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice, coluna in acc_df.iterrows():\n",
    "        user_distancex = coluna.iloc[0]\n",
    "        user_distancey = coluna.iloc[1]\n",
    "        user_distancez = coluna.iloc[2]\n",
    "        vetor.append(math.sqrt(user_distancex**2 + user_distancey**2 + user_distancez**2))\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_info_EDA(eda):\n",
    "    eda_df= pd.read_csv(eda, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in eda_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_info_HR(hr):\n",
    "    hr_df= pd.read_csv(hr, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in hr_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_info_TEMP(temp):\n",
    "    temp_df= pd.read_csv(temp, skiprows=1)\n",
    "    vetor = []\n",
    "    for indice,coluna in temp_df.iterrows():\n",
    "        vetor.append(coluna.iloc[0])\n",
    "\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "caminho_raiz = r'C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D'\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "        data_ACC, data_EDA, data_HR, data_TEMP = None, None, None, None\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "        nova_linha = {'ID': id, 'TIMESTAMP': timestamp, 'ACC': data_ACC, 'EDA': data_EDA, 'HR': data_HR, 'TEMP': data_TEMP, 'STRESS': np.nan}\n",
    "\n",
    "        array = np.array(list(nova_linha.values()), dtype=object)\n",
    "        array_t = np.transpose(array)\n",
    "###### Tenta transformar em um np array, dar o transpose e concatenar como vc fez com o pd.concat\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([array_t])], ignore_index=True)\n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "caminho_raiz = r'C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D'\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "cont = 0\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        \n",
    "        id, timestamp, data_ACC, data_EDA, data_HR, data_TEMP = None, None, None, None, None, None\n",
    "\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "            if cont==0:\n",
    "                df['ID'] = id\n",
    "                df['TIMESTAMP'] = timestamp\n",
    "                df['ACC'] = data_ACC\n",
    "                df['EDA'] = data_EDA\n",
    "                df['HR'] = data_HR\n",
    "                df['TEMP'] = data_TEMP\n",
    "                df['STRESS'] = np.nan\n",
    "                cont = cont + 1\n",
    "            # else:\n",
    "            #     # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([timestamp])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_ACC])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_EDA])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_HR])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_TEMP])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "\n",
    "                # df.append(pd.DataFrame({'ID': id}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TIMESTAMP': timestamp}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'ACC': data_ACC}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'EDA': data_EDA}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'HR': data_HR}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TEMP': data_TEMP}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'STRESS': np.nan}), ignore_index=True)\n",
    "            \n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data_TEMP \u001b[39m=\u001b[39m get_info_EDA(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(caminho_pasta, arquivo))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Convertendo strings para listas usando ast.literal_eval\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mACC\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39;49mliteral_eval(data[\u001b[39m\"\u001b[39;49m\u001b[39mACC\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mEDA\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mliteral_eval(data[\u001b[39m\"\u001b[39m\u001b[39mEDA\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsa3/Downloads/doi_10.5061_dryad.5hqbzkh6f__v6/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mHR\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mliteral_eval(data[\u001b[39m\"\u001b[39m\u001b[39mHR\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Constant) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mvalue) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m lno \u001b[39m:=\u001b[39m \u001b[39mgetattr\u001b[39m(node, \u001b[39m'\u001b[39m\u001b[39mlineno\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m on line \u001b[39m\u001b[39m{\u001b[39;00mlno\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: []"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "caminho_raiz = r'C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\6D'\n",
    "df = pd.DataFrame(columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n",
    "cont = 0\n",
    "\n",
    "data = {\n",
    "        'ID': [],\n",
    "        'TIMESTAMP': [],\n",
    "        'ACC': [],\n",
    "        'EDA': [],\n",
    "        'HR': [],\n",
    "        'TEMP': [],\n",
    "        'STRESS': []\n",
    "        }\n",
    "\n",
    "for pasta in os.listdir(caminho_raiz):\n",
    "    caminho_pasta = os.path.join(caminho_raiz, pasta)\n",
    "\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        \n",
    "        stress = []\n",
    "        id = get_id(caminho_pasta)\n",
    "        timestamp = get_timestamp(caminho_pasta)\n",
    "\n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            if arquivo == 'ACC.csv':\n",
    "                data_ACC = get_info_ACC(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'EDA.csv':\n",
    "                data_EDA = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'HR.csv':\n",
    "                data_HR = get_info_HR(os.path.join(caminho_pasta, arquivo))\n",
    "            elif arquivo == 'TEMP.csv':\n",
    "                data_TEMP = get_info_EDA(os.path.join(caminho_pasta, arquivo))\n",
    "\n",
    "            # Convertendo strings para listas usando ast.literal_eval\n",
    "            data[\"ACC\"] = ast.literal_eval(data[\"ACC\"])\n",
    "            data[\"EDA\"] = ast.literal_eval(data[\"EDA\"])\n",
    "            data[\"HR\"] = ast.literal_eval(data[\"HR\"])\n",
    "            data[\"TEMP\"] = ast.literal_eval(data[\"TEMP\"])\n",
    "            data[\"STRESS\"] = ast.literal_eval(data[\"STRESS\"])\n",
    "            # Convertendo para DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "            # Criando uma nova linha para cada elemento nas listas\n",
    "            df = df.apply(lambda col: col.apply(pd.Series)).stack().reset_index(level=1, drop=True).to_frame().join(df.drop([\"ACC\", \"EDA\", \"HR\", \"TEMP\", \"STRESS\"], axis=1))\n",
    "            df = df.reset_index().rename(columns={0: \"VALUE\"})\n",
    "\n",
    "\n",
    "            # else:\n",
    "            #     # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([timestamp])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_ACC])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_EDA])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_HR])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([data_TEMP])], ignore_index=True)\n",
    "            #     df = pd.concat([df, pd.DataFrame([id])], ignore_index=True)\n",
    "\n",
    "                # df.append(pd.DataFrame({'ID': id}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TIMESTAMP': timestamp}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'ACC': data_ACC}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'EDA': data_EDA}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'HR': data_HR}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'TEMP': data_TEMP}), ignore_index=True)\n",
    "                # df.append(pd.DataFrame({'STRESS': np.nan}), ignore_index=True)\n",
    "            \n",
    "\n",
    "\n",
    "df.to_csv(\"6Dagain6.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1594141473', '1594217466', '1594218280', '1594223270', '1594235058', '1594390055', '1594402134', '1594403655', '1594647650', '1594671025', '1594746945', '1594758671', '1594820907', '1594825280', '1594830652', '1594843057', '1594920460', '1594927034', '1594932553', '1594934714', '1594934801', '1594996818', '1595014348', '1595254546', '1595272717', '1595337790', '1595344020', '1595351362', '1595358823', '1595421778', '1595438005', '1595439251', '1595514881', '1595515035', '1595533978']\n"
     ]
    }
   ],
   "source": [
    "# Importing Pandas to create DataFrame \n",
    "import pandas as pd \n",
    "\n",
    "pasta = r'C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5'\n",
    "# column[0] = get_id_timestamp\n",
    "# column[1] = get_id_timestamp\n",
    "# column[2] = \n",
    "# column[3] = \n",
    "\n",
    "print(get_id_timestamp(pasta))\n",
    "#data = main(r'C:\\Users\\lsa3\\Downloads\\doi_10.5061_dryad.5hqbzkh6f__v6\\Stress_dataset\\F5')\n",
    "# Creating Empty DataFrame and Storing it in variable df \n",
    "#new_df = pd.DataFrame(data, columns=['ID', 'TIMESTAMP', 'ACC', 'EDA', 'HR', 'TEMP', 'STRESS'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
